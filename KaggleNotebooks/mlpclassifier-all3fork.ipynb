{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b438605b",
   "metadata": {
    "papermill": {
     "duration": 0.006676,
     "end_time": "2023-04-01T04:35:41.566239",
     "exception": false,
     "start_time": "2023-04-01T04:35:41.559563",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Acceleroseismology: A model for identifying FoG in Parkinson's Disease patients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13180ab9",
   "metadata": {
    "papermill": {
     "duration": 0.004705,
     "end_time": "2023-04-01T04:35:41.576168",
     "exception": false,
     "start_time": "2023-04-01T04:35:41.571463",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Background:\n",
    "\n",
    "Freezing of Gait is a symptom of Parkinson's Disease (PD) that is debilitating, lowers quality of life, reduces independence, and can lead to an increased risk of falling.  In an effort to identify Freezing of Gait signatures in accelerometer data (or better yet, predict occurences ahead of time), this notebook applies a machine learning algorithm to the time series accelerometry.  I hope the results are useful in diagnosing and potentially warning PD patients ahead of Freezing of Gait (FoG) episodes.\n",
    "\n",
    "\n",
    "## Acceleroseismology:\n",
    "\n",
    "As a mental model, I have approached this problem similar to seismology.  In studying earthquakes, seismologists discovered that P-waves arrive ahead of more destructive S-waves, allowing for an early warning system to avoid adverse effects.  Similarly, in what I am calling acceleroseismology, I analyze both time and frequency domain features in accelerometry data via a moving window approach in order to place each instance of time in its broader context.  Ultimately, I hope to engineer relevant features that can predict the coming onset of a FoG episode, as such a capability could enable wearable devices to alert the user and possibly reduce fall risk and improve the probability of avoiding the FoG event altogether.  Such a result would contribute to the United Nations' [Third Sustainable Development Goal: Good health and well-being](https://sdgs.un.org/goals).\n",
    "\n",
    "\n",
    "## Motivation Behind Features:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c635f22",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-04-01T04:35:41.589572Z",
     "iopub.status.busy": "2023-04-01T04:35:41.588750Z",
     "iopub.status.idle": "2023-04-01T04:35:43.059811Z",
     "shell.execute_reply": "2023-04-01T04:35:43.058403Z"
    },
    "papermill": {
     "duration": 1.482217,
     "end_time": "2023-04-01T04:35:43.063248",
     "exception": false,
     "start_time": "2023-04-01T04:35:41.581031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import Libraries:\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "#import random\n",
    "import csv\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "#from sklearn.ensemble import RandomForestRegressor\n",
    "#from sklearn.metrics import mean_absolute_error\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "####################################################################\n",
    "########               PARAMETERS & CONSTANTS:               ########\n",
    "####################################################################\n",
    "sampleRateTDCSFOG = 128     #per second\n",
    "sampleRateDEFOG = 100     #per second\n",
    "windowHalfLength = 21 #on either side of the point of interest (for the moving window)\n",
    "peakThreshold = 1.4  #peakThreshold*mean value identifies a peak\n",
    "\n",
    "#low frequency band\n",
    "lowfBandMin = 0.0\n",
    "lowfBandMax = 2.0\n",
    "#high frequency band\n",
    "highfBandMin = 2.0\n",
    "highfBandMax = 6.0\n",
    "\n",
    "dummyVariable = 9 #ignore this for now, please.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423a055d",
   "metadata": {
    "papermill": {
     "duration": 0.004148,
     "end_time": "2023-04-01T04:35:43.072454",
     "exception": false,
     "start_time": "2023-04-01T04:35:43.068306",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Functions:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "941448a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:35:43.084734Z",
     "iopub.status.busy": "2023-04-01T04:35:43.083300Z",
     "iopub.status.idle": "2023-04-01T04:35:43.098992Z",
     "shell.execute_reply": "2023-04-01T04:35:43.097629Z"
    },
    "papermill": {
     "duration": 0.025404,
     "end_time": "2023-04-01T04:35:43.102298",
     "exception": false,
     "start_time": "2023-04-01T04:35:43.076894",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#A fxn that computes the root mean abs square value of an array.\n",
    "def getRMS(inputArray):\n",
    "    return np.sqrt(np.mean(abs(inputArray)*abs(inputArray))) #imaginary args okay\n",
    "\n",
    "\n",
    "#A low pass filter to remove high frequency noise.\n",
    "def lowPassFilter(kArr, freqArr, cutOffFreq):\n",
    "    for i in range(0,len(freqArr)):\n",
    "        if freqArr[i] > cutOffFreq:\n",
    "            kArr.real[i] = 0; \n",
    "            kArr.imag[i] = 0;\n",
    "    return kArr\n",
    "\n",
    "\n",
    "#A high pass filter to analyze only high frequencies.  \n",
    "def highPassFilter(kArr, freqArr, cutOffFreq):\n",
    "    for i in range(0,len(freqArr)):\n",
    "        if freqArr[i] < cutOffFreq:\n",
    "            kArr.real[i] = 0;\n",
    "            kArr.imag[i] = 0;\n",
    "    return kArr\n",
    "\n",
    "\n",
    "#A quick FFT where W can be x, y, z accelerations etc.\n",
    "def quickFFT(inputT, inputW, sampleRate, filterType, cutOff):\n",
    "    kspaceData = np.fft.rfft(inputW)\n",
    "    freq = np.fft.rfftfreq(inputT.shape[-1], d=1.0/sampleRate)\n",
    "    if filterType == \"low\":\n",
    "        filteredData = lowPassFilter(kspaceData, freq, cutOff)\n",
    "    elif filterType == \"high\":\n",
    "        filteredData = highPassFilter(kspaceData, freq, cutOff)\n",
    "    else:\n",
    "        filteredData = kspaceData\n",
    "    outputW = np.fft.irfft(filteredData, len(inputW))\n",
    "    return outputW\n",
    "\n",
    "\n",
    "#A quick FFT where W can be x, y, z accelerations etc. (returns k-space)\n",
    "def quickFFT_k(inputT, inputW, sampleRate, filterType, cutOff):\n",
    "    kspaceData = np.fft.rfft(inputW)\n",
    "    freq = np.fft.rfftfreq(inputT.shape[-1], d=1.0/sampleRate)\n",
    "    if filterType == \"low\":\n",
    "        filteredData = lowPassFilter(kspaceData, freq, cutOff)\n",
    "    elif filterType == \"high\":\n",
    "        filteredData = highPassFilter(kspaceData, freq, cutOff)\n",
    "    else:\n",
    "        filteredData = kspaceData\n",
    "    return freq, filteredData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878370d2",
   "metadata": {
    "papermill": {
     "duration": 0.0044,
     "end_time": "2023-04-01T04:35:43.111495",
     "exception": false,
     "start_time": "2023-04-01T04:35:43.107095",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Read in training data:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68f1c720",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:35:43.124150Z",
     "iopub.status.busy": "2023-04-01T04:35:43.122655Z",
     "iopub.status.idle": "2023-04-01T04:35:43.128841Z",
     "shell.execute_reply": "2023-04-01T04:35:43.127927Z"
    },
    "papermill": {
     "duration": 0.015131,
     "end_time": "2023-04-01T04:35:43.131399",
     "exception": false,
     "start_time": "2023-04-01T04:35:43.116268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the training and testing data:\n",
    "#train_file_path = '/kaggle/input/parkinsonsfog-newfeatures-traintest/trainFinal.csv'\n",
    "#test_file_path = '/kaggle/input/parkinsonsfog-newfeatures-traintest/testFinal.csv'\n",
    "\n",
    "trainTDCSFOG_path = '/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/train/tdcsfog/'\n",
    "trainDEFOG_path = '/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/train/defog/'\n",
    "\n",
    "testTDCSFOG_path = '/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/test/tdcsfog/'\n",
    "testDEFOG_path = '/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/test/defog/'\n",
    "\n",
    "\n",
    "#print(\"Reading training file...\")\n",
    "#trainTDCSFOG_data = pd.read_csv(trainTDCSFOG_path)\n",
    "#test_data = pd.read_csv(test_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54903e10",
   "metadata": {
    "papermill": {
     "duration": 0.004261,
     "end_time": "2023-04-01T04:35:43.140429",
     "exception": false,
     "start_time": "2023-04-01T04:35:43.136168",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Process data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b336538e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:35:43.152692Z",
     "iopub.status.busy": "2023-04-01T04:35:43.152157Z",
     "iopub.status.idle": "2023-04-01T06:45:03.020927Z",
     "shell.execute_reply": "2023-04-01T06:45:03.018998Z"
    },
    "papermill": {
     "duration": 7759.880132,
     "end_time": "2023-04-01T06:45:03.025181",
     "exception": false,
     "start_time": "2023-04-01T04:35:43.145049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating TDCS list...\n",
      "Creating DEFOG list...\n"
     ]
    }
   ],
   "source": [
    "colNames_TDCS = ['Time', 'aVert', 'aML', 'aAP', 'StartHesitation', 'Turn', 'Walking', 'id_t']\n",
    "colNames_DEFOG = ['Time', 'aVert', 'aML', 'aAP', 'StartHesitation', 'Turn', 'Walking', 'Valid', 'Task', 'id_t']\n",
    "\n",
    "trainTDCS_List = []\n",
    "trainDEFOG_List = []\n",
    "\n",
    "#Process data:\n",
    "print('Creating TDCS list...')\n",
    "for dirname, _, filenames in os.walk(trainTDCSFOG_path):\n",
    "    for filename in filenames:\n",
    "        #print(my_files_path+filename)\n",
    "        id = filename[:-4] #removes trailing .csv\n",
    "        f_trainTDCS_List = [] #file specific list, add elements to main list later\n",
    "        with open(trainTDCSFOG_path+filename) as file_obj:\n",
    "            heading = next(file_obj)\n",
    "            reader_obj = csv.reader(file_obj)   \n",
    "            # Iterate over each row in the csv file:\n",
    "            for row in reader_obj:\n",
    "                id_t = id + \"_\" + str(row[0])\n",
    "                row.append(id_t)\n",
    "                f_trainTDCS_List.append(row)\n",
    "        #File specific list is f_trainTDCS_List\n",
    "        #Feature engineering now begins for the file:\n",
    "        numPoints = len(f_trainTDCS_List)\n",
    "        dfTemp = pd.DataFrame(f_trainTDCS_List,columns=colNames_TDCS)\n",
    "        t = np.array(dfTemp['Time'].astype('float64'))\n",
    "        aML = np.array(dfTemp['aML'].astype('float64'))\n",
    "        aAP = np.array(dfTemp['aAP'].astype('float64'))\n",
    "        aVert = np.array(dfTemp['aVert'].astype('float64'))\n",
    "        boolStartHes = np.array(dfTemp['StartHesitation'])\n",
    "        boolTurn = np.array(dfTemp['Turn'])\n",
    "        boolWalking = np.array(dfTemp['Walking'])  \n",
    "        id_t = dfTemp['id_t']\n",
    "        #Initialize arrays:\n",
    "        maxAmpAP         = np.zeros(numPoints) # abs val of maximum amplitude in FFT'd AP data\n",
    "        maxAccelAmpML    = np.zeros(numPoints) # abs(max - min accel) for ML accel data\n",
    "        maxAccelAmpAP    = np.zeros(numPoints) # abs(max - min accel) for AP accel data\n",
    "        maxAccelAmpVert  = np.zeros(numPoints) # abs(max - min accel) for Vert accel data\n",
    "        rmsAmpsLowfAP    = np.zeros(numPoints) # root-mean-square (rms) of amplitudes in low freq band (AP)\n",
    "        rmsAmpsLowfVert  = np.zeros(numPoints) # root-mean-square (rms) of amplitudes in low freq band (vert)\n",
    "        rmsAmpsHighfML   = np.zeros(numPoints) # root-mean-square (rms) of amplitudes in high freq band (ML)\n",
    "        for tm in range(windowHalfLength, numPoints-windowHalfLength-1):\n",
    "            tClip = t[tm-windowHalfLength:tm+windowHalfLength+1]\n",
    "            aML_Clip = aML[tm-windowHalfLength:tm+windowHalfLength+1]\n",
    "            aAP_Clip = aAP[tm-windowHalfLength:tm+windowHalfLength+1]\n",
    "            aVert_Clip = aVert[tm-windowHalfLength:tm+windowHalfLength+1]\n",
    "            freqML, ampsML = quickFFT_k(tClip, aML_Clip, sampleRateTDCSFOG, \"none\", dummyVariable)\n",
    "            freqAP, ampsAP = quickFFT_k(tClip, aAP_Clip, sampleRateTDCSFOG, \"none\", dummyVariable)\n",
    "            freqVert, ampsVert = quickFFT_k(tClip, aVert_Clip, sampleRateTDCSFOG, \"none\", dummyVariable)\n",
    "            meanAccelML   = np.nanmean(abs(aML_Clip))     #Mean abs acceleration in the ML direction during time window\n",
    "            meanAccelAP   = np.nanmean(abs(aAP_Clip))     #Mean abs acceleration in the AP direction during time window\n",
    "            meanAccelVert = np.nanmean(abs(aVert_Clip))   #Mean abs acceleration in the Vert direction during time window\n",
    "            absAmpsML     = abs(ampsML)\n",
    "            absAmpsAP     = abs(ampsAP)\n",
    "            absAmpsVert   = abs(ampsVert)\n",
    "            meanAmpML     = np.nanmean(absAmpsML)       #Mean abs amplitude for ML data (FFT'd)\n",
    "            meanAmpAP     = np.nanmean(absAmpsAP)       #Mean abs amplitude for AP data (FFT'd)\n",
    "            meanAmpVert   = np.nanmean(absAmpsVert)     #Mean abs amplitude for Vert data (FFT'd)\n",
    "            #Start Filling Arrays:\n",
    "            maxAmpAP[tm] = np.amax(absAmpsAP,axis=0)     # abs val of maximum amplitude in FFT'd AP data\n",
    "            maxAccelAmpML[tm] = np.max(abs(aML_Clip)) - np.min(abs(aML_Clip))       # abs(max - min accel) for ML accel data\n",
    "            maxAccelAmpAP[tm] = np.max(abs(aAP_Clip)) - np.min(abs(aAP_Clip))       # abs(max - min accel) for AP accel data\n",
    "            maxAccelAmpVert[tm] = np.max(abs(aVert_Clip)) - np.min(abs(aVert_Clip)) # abs(max - min accel) for Vert accel data\n",
    "            rmsAmpsLowfAP[tm] = getRMS(ampsAP[freqAP<lowfBandMax])\n",
    "            rmsAmpsLowfVert[tm] = getRMS(ampsVert[freqVert<lowfBandMax])\n",
    "            rmsAmpsHighfML[tm] = getRMS(ampsML[(freqML>highfBandMin)*(freqML<highfBandMax)])\n",
    "        for dt in range(0, numPoints):  \n",
    "            addThis = []\n",
    "            addThis.append(maxAmpAP[dt])\n",
    "            addThis.append(maxAccelAmpML[dt])\n",
    "            addThis.append(maxAccelAmpAP[dt])\n",
    "            addThis.append(maxAccelAmpVert[dt])\n",
    "            addThis.append(rmsAmpsLowfAP[dt])\n",
    "            addThis.append(rmsAmpsLowfVert[dt])\n",
    "            addThis.append(rmsAmpsHighfML[dt])\n",
    "            #Finally, add the bools to the end:\n",
    "            addThis.append(boolStartHes[dt])\n",
    "            addThis.append(boolTurn[dt])\n",
    "            addThis.append(boolWalking[dt])\n",
    "            addThis.append(id_t[dt])\n",
    "            trainTDCS_List.append(addThis)\n",
    "\n",
    "            \n",
    "print('Creating DEFOG list...')\n",
    "for dirname, _, filenames in os.walk(trainDEFOG_path):\n",
    "    for filename in filenames:\n",
    "        #print(my_files_path+filename)\n",
    "        id = filename[:-4] #removes trailing .csv\n",
    "        f_trainDEFOG_List = [] #file specific list, add elements to main list later\n",
    "        with open(trainDEFOG_path+filename) as file_obj:\n",
    "            heading = next(file_obj)\n",
    "            reader_obj = csv.reader(file_obj)   \n",
    "            # Iterate over each row in the csv file:\n",
    "            for row in reader_obj:\n",
    "                id_t = id + \"_\" + str(row[0])\n",
    "                row.append(id_t)\n",
    "                f_trainDEFOG_List.append(row)\n",
    "        #File specific list is f_trainTDCS_List\n",
    "        #Feature engineering now begins for the file:\n",
    "        numPoints = len(f_trainDEFOG_List)\n",
    "        dfTemp = pd.DataFrame(f_trainDEFOG_List,columns=colNames_DEFOG)\n",
    "        t = np.array(dfTemp['Time'].astype('float64'))\n",
    "        aML = np.array(dfTemp['aML'].astype('float64'))\n",
    "        aAP = np.array(dfTemp['aAP'].astype('float64'))\n",
    "        aVert = np.array(dfTemp['aVert'].astype('float64'))\n",
    "        boolStartHes = np.array(dfTemp['StartHesitation'])\n",
    "        boolTurn = np.array(dfTemp['Turn'])\n",
    "        boolWalking = np.array(dfTemp['Walking'])  \n",
    "        id_t = dfTemp['id_t']\n",
    "        #Initialize arrays:\n",
    "        maxAmpAP         = np.zeros(numPoints) # abs val of maximum amplitude in FFT'd AP data\n",
    "        maxAccelAmpML    = np.zeros(numPoints) # abs(max - min accel) for ML accel data\n",
    "        maxAccelAmpAP    = np.zeros(numPoints) # abs(max - min accel) for AP accel data\n",
    "        maxAccelAmpVert  = np.zeros(numPoints) # abs(max - min accel) for Vert accel data\n",
    "        rmsAmpsLowfAP    = np.zeros(numPoints) # root-mean-square (rms) of amplitudes in low freq band (AP)\n",
    "        rmsAmpsLowfVert  = np.zeros(numPoints) # root-mean-square (rms) of amplitudes in low freq band (vert)\n",
    "        rmsAmpsHighfML   = np.zeros(numPoints) # root-mean-square (rms) of amplitudes in high freq band (ML)\n",
    "        for tm in range(windowHalfLength, numPoints-windowHalfLength-1):\n",
    "            tClip = t[tm-windowHalfLength:tm+windowHalfLength+1]\n",
    "            aML_Clip = aML[tm-windowHalfLength:tm+windowHalfLength+1]\n",
    "            aAP_Clip = aAP[tm-windowHalfLength:tm+windowHalfLength+1]\n",
    "            aVert_Clip = aVert[tm-windowHalfLength:tm+windowHalfLength+1]\n",
    "            freqML, ampsML = quickFFT_k(tClip, aML_Clip, sampleRateDEFOG, \"none\", dummyVariable)\n",
    "            freqAP, ampsAP = quickFFT_k(tClip, aAP_Clip, sampleRateDEFOG, \"none\", dummyVariable)\n",
    "            freqVert, ampsVert = quickFFT_k(tClip, aVert_Clip, sampleRateDEFOG, \"none\", dummyVariable)\n",
    "            meanAccelML   = np.nanmean(abs(aML_Clip))     #Mean abs acceleration in the ML direction during time window\n",
    "            meanAccelAP   = np.nanmean(abs(aAP_Clip))     #Mean abs acceleration in the AP direction during time window\n",
    "            meanAccelVert = np.nanmean(abs(aVert_Clip))   #Mean abs acceleration in the Vert direction during time window\n",
    "            absAmpsML     = abs(ampsML)\n",
    "            absAmpsAP     = abs(ampsAP)\n",
    "            absAmpsVert   = abs(ampsVert)\n",
    "            meanAmpML     = np.nanmean(absAmpsML)       #Mean abs amplitude for ML data (FFT'd)\n",
    "            meanAmpAP     = np.nanmean(absAmpsAP)       #Mean abs amplitude for AP data (FFT'd)\n",
    "            meanAmpVert   = np.nanmean(absAmpsVert)     #Mean abs amplitude for Vert data (FFT'd)\n",
    "            #Start Filling Arrays:\n",
    "            maxAmpAP[tm] = np.amax(absAmpsAP,axis=0)     # abs val of maximum amplitude in FFT'd AP data\n",
    "            maxAccelAmpML[tm] = np.max(abs(aML_Clip)) - np.min(abs(aML_Clip))       # abs(max - min accel) for ML accel data\n",
    "            maxAccelAmpAP[tm] = np.max(abs(aAP_Clip)) - np.min(abs(aAP_Clip))       # abs(max - min accel) for AP accel data\n",
    "            maxAccelAmpVert[tm] = np.max(abs(aVert_Clip)) - np.min(abs(aVert_Clip)) # abs(max - min accel) for Vert accel data\n",
    "            rmsAmpsLowfAP[tm] = getRMS(ampsAP[freqAP<lowfBandMax])\n",
    "            rmsAmpsLowfVert[tm] = getRMS(ampsVert[freqVert<lowfBandMax])\n",
    "            rmsAmpsHighfML[tm] = getRMS(ampsML[(freqML>highfBandMin)*(freqML<highfBandMax)])\n",
    "        for dt in range(0, numPoints):  \n",
    "            addThis = []\n",
    "            addThis.append(maxAmpAP[dt])\n",
    "            addThis.append(maxAccelAmpML[dt])\n",
    "            addThis.append(maxAccelAmpAP[dt])\n",
    "            addThis.append(maxAccelAmpVert[dt])\n",
    "            addThis.append(rmsAmpsLowfAP[dt])\n",
    "            addThis.append(rmsAmpsLowfVert[dt])\n",
    "            addThis.append(rmsAmpsHighfML[dt])\n",
    "            #Finally, add the bools to the end:\n",
    "            addThis.append(boolStartHes[dt])\n",
    "            addThis.append(boolTurn[dt])\n",
    "            addThis.append(boolWalking[dt])\n",
    "            addThis.append(id_t[dt])\n",
    "            trainDEFOG_List.append(addThis)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1b37cf",
   "metadata": {
    "papermill": {
     "duration": 0.004485,
     "end_time": "2023-04-01T06:45:03.035609",
     "exception": false,
     "start_time": "2023-04-01T06:45:03.031124",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Train the models:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14fdb949",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T06:45:03.048545Z",
     "iopub.status.busy": "2023-04-01T06:45:03.047611Z",
     "iopub.status.idle": "2023-04-01T07:02:40.630508Z",
     "shell.execute_reply": "2023-04-01T07:02:40.627772Z"
    },
    "papermill": {
     "duration": 1057.5973,
     "end_time": "2023-04-01T07:02:40.637937",
     "exception": false,
     "start_time": "2023-04-01T06:45:03.040637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataframes...\n",
      "Training the TDCS model...\n",
      "Training the DEFOG model...\n"
     ]
    }
   ],
   "source": [
    "features = ['maxAmpAP', 'maxAccelAmpML', 'maxAccelAmpAP', 'maxAccelAmpVert', 'rmsAmpsLowfAP', 'rmsAmpsLowfVert', 'rmsAmpsHighfML']\n",
    "\n",
    "outputCols = ['StartHesitation', 'Turn', 'Walking']\n",
    "\n",
    "\n",
    "newColNames_TDCS = ['maxAmpAP', 'maxAccelAmpML', 'maxAccelAmpAP', 'maxAccelAmpVert', 'rmsAmpsLowfAP', 'rmsAmpsLowfVert', 'rmsAmpsHighfML', 'StartHesitation', 'Turn', 'Walking', 'id_t']\n",
    "newColNames_DEFOG = ['maxAmpAP', 'maxAccelAmpML', 'maxAccelAmpAP', 'maxAccelAmpVert', 'rmsAmpsLowfAP', 'rmsAmpsLowfVert', 'rmsAmpsHighfML', 'StartHesitation', 'Turn', 'Walking', 'id_t']\n",
    "\n",
    "\n",
    "                \n",
    "print('Creating dataframes...')\n",
    "dfTrain_TDCS = pd.DataFrame(trainTDCS_List, columns = newColNames_TDCS)\n",
    "dfTrain_DEFOG = pd.DataFrame(trainDEFOG_List, columns = newColNames_DEFOG)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#TDCS\n",
    "print(\"Training the TDCS model...\")\n",
    "X_TDCS = dfTrain_TDCS.loc[:, features] \n",
    "y_TDCS = dfTrain_TDCS.loc[:, outputCols]\n",
    "clf_TDCS = MultiOutputClassifier(LogisticRegression(max_iter=50000)).fit(X_TDCS, y_TDCS)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#DEFOG\n",
    "print(\"Training the DEFOG model...\")\n",
    "X_DEFOG = dfTrain_DEFOG.loc[:, features] \n",
    "y_DEFOG = dfTrain_DEFOG.loc[:, outputCols]\n",
    "clf_DEFOG = MultiOutputClassifier(LogisticRegression(max_iter=50000)).fit(X_DEFOG, y_DEFOG)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85da5d13",
   "metadata": {
    "papermill": {
     "duration": 0.012231,
     "end_time": "2023-04-01T07:02:40.663736",
     "exception": false,
     "start_time": "2023-04-01T07:02:40.651505",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Now Test the model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "104b023f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T07:02:40.694071Z",
     "iopub.status.busy": "2023-04-01T07:02:40.692152Z",
     "iopub.status.idle": "2023-04-01T07:04:26.402648Z",
     "shell.execute_reply": "2023-04-01T07:04:26.397265Z"
    },
    "papermill": {
     "duration": 105.731941,
     "end_time": "2023-04-01T07:04:26.408116",
     "exception": false,
     "start_time": "2023-04-01T07:02:40.676175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading testing files...\n",
      "Creating TDCS test list...\n",
      "Creating DEFOG test list...\n",
      "Creating dataframes...\n",
      "Making TDCS predictions...\n",
      "Making DEFOG predictions...\n"
     ]
    }
   ],
   "source": [
    "#Read in test data\n",
    "print(\"Reading testing files...\")\n",
    "#test_file_path_TDCS = '/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/test/tdcsfog/003f117e14.csv'\n",
    "#test_file_path_DEFOG = '/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/test/defog/02ab235146.csv'\n",
    "\n",
    "testTDCS_path = '/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/test/tdcsfog/'\n",
    "testDEFOG_path = '/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/test/defog/'\n",
    "\n",
    "testTDCS_List = []\n",
    "testDEFOG_List = []\n",
    "\n",
    "print('Creating TDCS test list...')\n",
    "for dirname, _, filenames in os.walk(testTDCS_path):\n",
    "    for filename in filenames:\n",
    "        #print(my_files_path+filename)\n",
    "        id = filename[:-4] #removes trailing .csv\n",
    "        f_testTDCS_List = [] #file specific list, add elements to main list later\n",
    "        with open(testTDCS_path+filename) as file_obj:\n",
    "            heading = next(file_obj)\n",
    "            reader_obj = csv.reader(file_obj)   \n",
    "            # Iterate over each row in the csv file:\n",
    "            for row in reader_obj:\n",
    "                id_t = id + \"_\" + str(row[0])\n",
    "                row.append(id_t)\n",
    "                f_testTDCS_List.append(row)\n",
    "        #Feature engineering now begins for the file:\n",
    "        numPoints = len(f_testTDCS_List)\n",
    "        dfTemp = pd.DataFrame(f_testTDCS_List,columns=['Time', 'aVert', 'aML', 'aAP', 'id_t'])\n",
    "        t = np.array(dfTemp['Time'].astype('float64'))\n",
    "        aML = np.array(dfTemp['aML'].astype('float64'))\n",
    "        aAP = np.array(dfTemp['aAP'].astype('float64'))\n",
    "        aVert = np.array(dfTemp['aVert'].astype('float64'))\n",
    "        id_t = dfTemp['id_t']\n",
    "        #Initialize arrays:\n",
    "        maxAmpAP         = np.zeros(numPoints) # abs val of maximum amplitude in FFT'd AP data\n",
    "        maxAccelAmpML    = np.zeros(numPoints) # abs(max - min accel) for ML accel data\n",
    "        maxAccelAmpAP    = np.zeros(numPoints) # abs(max - min accel) for AP accel data\n",
    "        maxAccelAmpVert  = np.zeros(numPoints) # abs(max - min accel) for Vert accel data\n",
    "        rmsAmpsLowfAP    = np.zeros(numPoints) # root-mean-square (rms) of amplitudes in low freq band (AP)\n",
    "        rmsAmpsLowfVert  = np.zeros(numPoints) # root-mean-square (rms) of amplitudes in low freq band (vert)\n",
    "        rmsAmpsHighfML   = np.zeros(numPoints) # root-mean-square (rms) of amplitudes in high freq band (ML)\n",
    "        for tm in range(windowHalfLength, numPoints-windowHalfLength-1):\n",
    "            tClip = t[tm-windowHalfLength:tm+windowHalfLength+1]\n",
    "            aML_Clip = aML[tm-windowHalfLength:tm+windowHalfLength+1]\n",
    "            aAP_Clip = aAP[tm-windowHalfLength:tm+windowHalfLength+1]\n",
    "            aVert_Clip = aVert[tm-windowHalfLength:tm+windowHalfLength+1]\n",
    "            freqML, ampsML = quickFFT_k(tClip, aML_Clip, sampleRateTDCSFOG, \"none\", dummyVariable)\n",
    "            freqAP, ampsAP = quickFFT_k(tClip, aAP_Clip, sampleRateTDCSFOG, \"none\", dummyVariable)\n",
    "            freqVert, ampsVert = quickFFT_k(tClip, aVert_Clip, sampleRateTDCSFOG, \"none\", dummyVariable)\n",
    "            meanAccelML   = np.nanmean(abs(aML_Clip))     #Mean abs acceleration in the ML direction during time window\n",
    "            meanAccelAP   = np.nanmean(abs(aAP_Clip))     #Mean abs acceleration in the AP direction during time window\n",
    "            meanAccelVert = np.nanmean(abs(aVert_Clip))   #Mean abs acceleration in the Vert direction during time window\n",
    "            absAmpsML     = abs(ampsML)\n",
    "            absAmpsAP     = abs(ampsAP)\n",
    "            absAmpsVert   = abs(ampsVert)\n",
    "            meanAmpML     = np.nanmean(absAmpsML)       #Mean abs amplitude for ML data (FFT'd)\n",
    "            meanAmpAP     = np.nanmean(absAmpsAP)       #Mean abs amplitude for AP data (FFT'd)\n",
    "            meanAmpVert   = np.nanmean(absAmpsVert)     #Mean abs amplitude for Vert data (FFT'd)\n",
    "            #Start Filling Arrays:\n",
    "            maxAmpAP[tm] = np.amax(absAmpsAP,axis=0)     # abs val of maximum amplitude in FFT'd AP data\n",
    "            maxAccelAmpML[tm] = np.max(abs(aML_Clip)) - np.min(abs(aML_Clip))       # abs(max - min accel) for ML accel data\n",
    "            maxAccelAmpAP[tm] = np.max(abs(aAP_Clip)) - np.min(abs(aAP_Clip))       # abs(max - min accel) for AP accel data\n",
    "            maxAccelAmpVert[tm] = np.max(abs(aVert_Clip)) - np.min(abs(aVert_Clip)) # abs(max - min accel) for Vert accel data\n",
    "            rmsAmpsLowfAP[tm] = getRMS(ampsAP[freqAP<lowfBandMax])\n",
    "            rmsAmpsLowfVert[tm] = getRMS(ampsVert[freqVert<lowfBandMax])\n",
    "            rmsAmpsHighfML[tm] = getRMS(ampsML[(freqML>highfBandMin)*(freqML<highfBandMax)])\n",
    "        for dt in range(0, numPoints):  \n",
    "            addThis = []\n",
    "            addThis.append(maxAmpAP[dt])\n",
    "            addThis.append(maxAccelAmpML[dt])\n",
    "            addThis.append(maxAccelAmpAP[dt])\n",
    "            addThis.append(maxAccelAmpVert[dt])\n",
    "            addThis.append(rmsAmpsLowfAP[dt])\n",
    "            addThis.append(rmsAmpsLowfVert[dt])\n",
    "            addThis.append(rmsAmpsHighfML[dt])\n",
    "            addThis.append(id_t[dt])\n",
    "            testTDCS_List.append(addThis)\n",
    "\n",
    "\n",
    "\n",
    "print('Creating DEFOG test list...')\n",
    "for dirname, _, filenames in os.walk(testDEFOG_path):\n",
    "    for filename in filenames:\n",
    "        #print(my_files_path+filename)\n",
    "        id = filename[:-4] #removes trailing .csv\n",
    "        f_testDEFOG_List = [] #file specific list, add elements to main list later\n",
    "        with open(testDEFOG_path+filename) as file_obj:\n",
    "            heading = next(file_obj)\n",
    "            reader_obj = csv.reader(file_obj)   \n",
    "            # Iterate over each row in the csv file:\n",
    "            for row in reader_obj:\n",
    "                id_t = id + \"_\" + str(row[0])\n",
    "                row.append(id_t)\n",
    "                f_testDEFOG_List.append(row)\n",
    "        #Feature engineering now begins for the file:\n",
    "        numPoints = len(f_testDEFOG_List)\n",
    "        dfTemp = pd.DataFrame(f_testDEFOG_List,columns=['Time', 'aVert', 'aML', 'aAP', 'id_t'])\n",
    "        t = np.array(dfTemp['Time'].astype('float64'))\n",
    "        aML = np.array(dfTemp['aML'].astype('float64'))\n",
    "        aAP = np.array(dfTemp['aAP'].astype('float64'))\n",
    "        aVert = np.array(dfTemp['aVert'].astype('float64')) \n",
    "        id_t = dfTemp['id_t']\n",
    "        #Initialize arrays:\n",
    "        maxAmpAP         = np.zeros(numPoints) # abs val of maximum amplitude in FFT'd AP data\n",
    "        maxAccelAmpML    = np.zeros(numPoints) # abs(max - min accel) for ML accel data\n",
    "        maxAccelAmpAP    = np.zeros(numPoints) # abs(max - min accel) for AP accel data\n",
    "        maxAccelAmpVert  = np.zeros(numPoints) # abs(max - min accel) for Vert accel data\n",
    "        rmsAmpsLowfAP    = np.zeros(numPoints) # root-mean-square (rms) of amplitudes in low freq band (AP)\n",
    "        rmsAmpsLowfVert  = np.zeros(numPoints) # root-mean-square (rms) of amplitudes in low freq band (vert)\n",
    "        rmsAmpsHighfML   = np.zeros(numPoints) # root-mean-square (rms) of amplitudes in high freq band (ML)\n",
    "        for tm in range(windowHalfLength, numPoints-windowHalfLength-1):\n",
    "            tClip = t[tm-windowHalfLength:tm+windowHalfLength+1]\n",
    "            aML_Clip = aML[tm-windowHalfLength:tm+windowHalfLength+1]\n",
    "            aAP_Clip = aAP[tm-windowHalfLength:tm+windowHalfLength+1]\n",
    "            aVert_Clip = aVert[tm-windowHalfLength:tm+windowHalfLength+1]\n",
    "            freqML, ampsML = quickFFT_k(tClip, aML_Clip, sampleRateDEFOG, \"none\", dummyVariable)\n",
    "            freqAP, ampsAP = quickFFT_k(tClip, aAP_Clip, sampleRateDEFOG, \"none\", dummyVariable)\n",
    "            freqVert, ampsVert = quickFFT_k(tClip, aVert_Clip, sampleRateDEFOG, \"none\", dummyVariable)\n",
    "            meanAccelML   = np.nanmean(abs(aML_Clip))     #Mean abs acceleration in the ML direction during time window\n",
    "            meanAccelAP   = np.nanmean(abs(aAP_Clip))     #Mean abs acceleration in the AP direction during time window\n",
    "            meanAccelVert = np.nanmean(abs(aVert_Clip))   #Mean abs acceleration in the Vert direction during time window\n",
    "            absAmpsML     = abs(ampsML)\n",
    "            absAmpsAP     = abs(ampsAP)\n",
    "            absAmpsVert   = abs(ampsVert)\n",
    "            meanAmpML     = np.nanmean(absAmpsML)       #Mean abs amplitude for ML data (FFT'd)\n",
    "            meanAmpAP     = np.nanmean(absAmpsAP)       #Mean abs amplitude for AP data (FFT'd)\n",
    "            meanAmpVert   = np.nanmean(absAmpsVert)     #Mean abs amplitude for Vert data (FFT'd)\n",
    "            #Start Filling Arrays:\n",
    "            maxAmpAP[tm] = np.amax(absAmpsAP,axis=0)     # abs val of maximum amplitude in FFT'd AP data\n",
    "            maxAccelAmpML[tm] = np.max(abs(aML_Clip)) - np.min(abs(aML_Clip))       # abs(max - min accel) for ML accel data\n",
    "            maxAccelAmpAP[tm] = np.max(abs(aAP_Clip)) - np.min(abs(aAP_Clip))       # abs(max - min accel) for AP accel data\n",
    "            maxAccelAmpVert[tm] = np.max(abs(aVert_Clip)) - np.min(abs(aVert_Clip)) # abs(max - min accel) for Vert accel data\n",
    "            rmsAmpsLowfAP[tm] = getRMS(ampsAP[freqAP<lowfBandMax])\n",
    "            rmsAmpsLowfVert[tm] = getRMS(ampsVert[freqVert<lowfBandMax])\n",
    "            rmsAmpsHighfML[tm] = getRMS(ampsML[(freqML>highfBandMin)*(freqML<highfBandMax)])\n",
    "        for dt in range(0, numPoints):  \n",
    "            addThis = []\n",
    "            addThis.append(maxAmpAP[dt])\n",
    "            addThis.append(maxAccelAmpML[dt])\n",
    "            addThis.append(maxAccelAmpAP[dt])\n",
    "            addThis.append(maxAccelAmpVert[dt])\n",
    "            addThis.append(rmsAmpsLowfAP[dt])\n",
    "            addThis.append(rmsAmpsLowfVert[dt])\n",
    "            addThis.append(rmsAmpsHighfML[dt])\n",
    "            #Finally, add the bools to the end:\n",
    "            addThis.append(id_t[dt])\n",
    "            testDEFOG_List.append(addThis)\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "print('Creating dataframes...')\n",
    "dfTest_TDCS = pd.DataFrame(testTDCS_List, columns = ['maxAmpAP', 'maxAccelAmpML', 'maxAccelAmpAP', 'maxAccelAmpVert', 'rmsAmpsLowfAP', 'rmsAmpsLowfVert', 'rmsAmpsHighfML', 'id_t'])\n",
    "dfTest_DEFOG = pd.DataFrame(testDEFOG_List, columns = ['maxAmpAP', 'maxAccelAmpML', 'maxAccelAmpAP', 'maxAccelAmpVert', 'rmsAmpsLowfAP', 'rmsAmpsLowfVert', 'rmsAmpsHighfML', 'id_t'])\n",
    "\n",
    "\n",
    "\n",
    "#TDCS\n",
    "X_val_TDCS = dfTest_TDCS.loc[:, features]\n",
    "print(\"Making TDCS predictions...\")\n",
    "clf_predictions_TDCS = clf_TDCS.predict(X_val_TDCS)\n",
    "df_clf_predictions_TDCS = pd.DataFrame(clf_predictions_TDCS, columns=outputCols)\n",
    "\n",
    "\n",
    "\n",
    "#DEFOG:\n",
    "X_val_DEFOG = dfTest_DEFOG.loc[:, features]\n",
    "print(\"Making DEFOG predictions...\")\n",
    "clf_predictions_DEFOG = clf_DEFOG.predict(X_val_DEFOG)\n",
    "df_clf_predictions_DEFOG = pd.DataFrame(clf_predictions_DEFOG, columns=outputCols)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23608bb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T07:04:26.438779Z",
     "iopub.status.busy": "2023-04-01T07:04:26.437649Z",
     "iopub.status.idle": "2023-04-01T07:04:26.882451Z",
     "shell.execute_reply": "2023-04-01T07:04:26.880951Z"
    },
    "papermill": {
     "duration": 0.464133,
     "end_time": "2023-04-01T07:04:26.886183",
     "exception": false,
     "start_time": "2023-04-01T07:04:26.422050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing submission file...\n"
     ]
    }
   ],
   "source": [
    "#store df of submission results.\n",
    "#finalList = [[] for _ in range(0, len(rf_val_predictions_Turn))]\n",
    "#or do df since we're just zipping?\n",
    "finalCols = ['id', 'StartHesitation', 'Turn', 'Walking']\n",
    "\n",
    "id_t_TDCS = dfTest_TDCS.loc[:, 'id_t']\n",
    "id_t_DEFOG = dfTest_TDCS.loc[:, 'id_t']\n",
    "\n",
    "df_clf_predictions_TDCS['id'] =  id_t_TDCS\n",
    "df_clf_predictions_DEFOG['id'] = id_t_DEFOG\n",
    "\n",
    "df_TDCS = df_clf_predictions_TDCS[finalCols]\n",
    "df_DEFOG = df_clf_predictions_DEFOG[finalCols]\n",
    "\n",
    "output_df = pd.concat([df_TDCS, df_DEFOG], ignore_index=True)\n",
    "   \n",
    "    \n",
    "print('Writing submission file...')\n",
    "output_df.to_csv(\"/kaggle/working/submission.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8942.855904,
   "end_time": "2023-04-01T07:04:31.047544",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-01T04:35:28.191640",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

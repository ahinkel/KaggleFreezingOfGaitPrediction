{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c9f6a64",
   "metadata": {
    "papermill": {
     "duration": 0.006403,
     "end_time": "2023-04-08T22:31:19.486708",
     "exception": false,
     "start_time": "2023-04-08T22:31:19.480305",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Acceleroseismology: A model for identifying FoG in Parkinson's Disease patients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d4b039",
   "metadata": {
    "papermill": {
     "duration": 0.004774,
     "end_time": "2023-04-08T22:31:19.496658",
     "exception": false,
     "start_time": "2023-04-08T22:31:19.491884",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Background:\n",
    "\n",
    "Freezing of Gait is a symptom of Parkinson's Disease (PD) that is debilitating, lowers quality of life, reduces independence, and can lead to an increased risk of falling.  In an effort to identify Freezing of Gait signatures in accelerometer data (or better yet, predict occurences ahead of time), this notebook applies a machine learning algorithm to the time series accelerometry.  I hope the results are useful in diagnosing and potentially warning PD patients ahead of Freezing of Gait (FoG) episodes.\n",
    "\n",
    "\n",
    "## Acceleroseismology:\n",
    "\n",
    "As a mental model, I have approached this problem similar to seismology.  In studying earthquakes, seismologists discovered that P-waves arrive ahead of more destructive S-waves, allowing for an early warning system to avoid adverse effects.  Similarly, in what I am calling acceleroseismology, I analyze both time and frequency domain features in accelerometry data via a moving window approach in order to place each instance of time in its broader context.  Ultimately, I hope to engineer relevant features that can predict the coming onset of a FoG episode, as such a capability could enable wearable devices to alert the user and possibly reduce fall risk and improve the probability of avoiding the FoG event altogether.  Such a result would contribute to the United Nations' [Third Sustainable Development Goal: Good health and well-being](https://sdgs.un.org/goals).\n",
    "\n",
    "\n",
    "## Motivation Behind Features:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56a7379d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-04-08T22:31:19.509857Z",
     "iopub.status.busy": "2023-04-08T22:31:19.509312Z",
     "iopub.status.idle": "2023-04-08T22:31:20.659339Z",
     "shell.execute_reply": "2023-04-08T22:31:20.658082Z"
    },
    "papermill": {
     "duration": 1.160072,
     "end_time": "2023-04-08T22:31:20.662446",
     "exception": false,
     "start_time": "2023-04-08T22:31:19.502374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import Libraries:\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "#import random\n",
    "import csv\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "#from sklearn.ensemble import RandomForestRegressor\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import average_precision_score\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "####################################################################\n",
    "########              PARAMETERS & CONSTANTS:               ########\n",
    "####################################################################\n",
    "sampleRateTDCSFOG = 128     #per second\n",
    "sampleRateDEFOG = 100     #per second\n",
    "windowHalfLength = 640 #on either side of the point of interest (for the moving window)\n",
    "Q_window = 200\n",
    "L_window = 400\n",
    "\n",
    "#low frequency band\n",
    "lowfBandMin = 0.0\n",
    "lowfBandMax = 2.0\n",
    "#high frequency band\n",
    "highfBandMin = 2.0\n",
    "highfBandMax = 6.0\n",
    "\n",
    "dummyVariable = 9 #ignore this for now, please.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb6b530",
   "metadata": {
    "papermill": {
     "duration": 0.004963,
     "end_time": "2023-04-08T22:31:20.672653",
     "exception": false,
     "start_time": "2023-04-08T22:31:20.667690",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Functions:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b23e5a7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-08T22:31:20.684878Z",
     "iopub.status.busy": "2023-04-08T22:31:20.684476Z",
     "iopub.status.idle": "2023-04-08T22:31:20.701709Z",
     "shell.execute_reply": "2023-04-08T22:31:20.700204Z"
    },
    "papermill": {
     "duration": 0.026937,
     "end_time": "2023-04-08T22:31:20.704642",
     "exception": false,
     "start_time": "2023-04-08T22:31:20.677705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#A fxn that computes the root mean abs square value of an array.\n",
    "def getRMS(inputArray):\n",
    "    return np.sqrt(np.mean(abs(inputArray)*abs(inputArray))) #imaginary args okay\n",
    "\n",
    "\n",
    "#A low pass filter to remove high frequency noise.\n",
    "def lowPassFilter(kArr, freqArr, cutOffFreq):\n",
    "    for i in range(0,len(freqArr)):\n",
    "        if freqArr[i] > cutOffFreq:\n",
    "            kArr.real[i] = 0; \n",
    "            kArr.imag[i] = 0;\n",
    "    return kArr\n",
    "\n",
    "\n",
    "#A high pass filter to analyze only high frequencies.  \n",
    "def highPassFilter(kArr, freqArr, cutOffFreq):\n",
    "    for i in range(0,len(freqArr)):\n",
    "        if freqArr[i] < cutOffFreq:\n",
    "            kArr.real[i] = 0;\n",
    "            kArr.imag[i] = 0;\n",
    "    return kArr\n",
    "\n",
    "\n",
    "#A quick FFT where W can be x, y, z accelerations etc.\n",
    "def quickFFT(inputT, inputW, sampleRate, filterType, cutOff):\n",
    "    kspaceData = np.fft.rfft(inputW)\n",
    "    freq = np.fft.rfftfreq(inputT.shape[-1], d=1.0/sampleRate)\n",
    "    if filterType == \"low\":\n",
    "        filteredData = lowPassFilter(kspaceData, freq, cutOff)\n",
    "    elif filterType == \"high\":\n",
    "        filteredData = highPassFilter(kspaceData, freq, cutOff)\n",
    "    else:\n",
    "        filteredData = kspaceData\n",
    "    outputW = np.fft.irfft(filteredData, len(inputW))\n",
    "    return outputW\n",
    "\n",
    "\n",
    "#A quick FFT where W can be x, y, z accelerations etc. (returns k-space)\n",
    "def quickFFT_k(inputT, inputW, sampleRate, filterType, cutOff):\n",
    "    kspaceData = np.fft.rfft(inputW)\n",
    "    freq = np.fft.rfftfreq(inputT.shape[-1], d=1.0/sampleRate)\n",
    "    if filterType == \"low\":\n",
    "        filteredData = lowPassFilter(kspaceData, freq, cutOff)\n",
    "    elif filterType == \"high\":\n",
    "        filteredData = highPassFilter(kspaceData, freq, cutOff)\n",
    "    else:\n",
    "        filteredData = kspaceData\n",
    "    return freq, filteredData\n",
    "\n",
    "#experimental feature: Loud amplitudes followed by quiescence \n",
    "def experiment1(inputT1, inputW1, inputT2, inputW2, sampleRate, filterType, cutOff):\n",
    "    freq1, amps1 = quickFFT_k(inputT1, inputW1, sampleRate, filterType, cutOff)\n",
    "    freq2, amps2 = quickFFT_k(inputT2, inputW2, sampleRate, filterType, cutOff)\n",
    "    temp1 = abs(amps1)*abs(amps1)\n",
    "    P1 = np.sum(temp1)\n",
    "    temp2 = abs(amps2)*abs(amps2)\n",
    "    P2 = np.sum(temp2)\n",
    "    return P2/(P1 + 0.01) #plus 0.01 is to avoid div by 0 for now, fix later.\n",
    "\n",
    "#experimental feature: rmsRadius_AP_Vert\n",
    "def experiment2(ap, vert):\n",
    "    return np.sqrt(ap*ap + vert*vert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea1e207",
   "metadata": {
    "papermill": {
     "duration": 0.004763,
     "end_time": "2023-04-08T22:31:20.714633",
     "exception": false,
     "start_time": "2023-04-08T22:31:20.709870",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Read in training data:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "899f6ba5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-08T22:31:20.727125Z",
     "iopub.status.busy": "2023-04-08T22:31:20.726697Z",
     "iopub.status.idle": "2023-04-08T22:31:20.732388Z",
     "shell.execute_reply": "2023-04-08T22:31:20.731187Z"
    },
    "papermill": {
     "duration": 0.014903,
     "end_time": "2023-04-08T22:31:20.734786",
     "exception": false,
     "start_time": "2023-04-08T22:31:20.719883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the training and testing data:\n",
    "#train_file_path = '/kaggle/input/parkinsonsfog-newfeatures-traintest/trainFinal.csv'\n",
    "#test_file_path = '/kaggle/input/parkinsonsfog-newfeatures-traintest/testFinal.csv'\n",
    "\n",
    "trainTDCSFOG_path = '/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/train/tdcsfog/'\n",
    "trainDEFOG_path = '/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/train/defog/'\n",
    "\n",
    "testTDCSFOG_path = '/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/test/tdcsfog/'\n",
    "testDEFOG_path = '/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/test/defog/'\n",
    "\n",
    "\n",
    "#print(\"Reading training file...\")\n",
    "#trainTDCSFOG_data = pd.read_csv(trainTDCSFOG_path)\n",
    "#test_data = pd.read_csv(test_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcee30e",
   "metadata": {
    "papermill": {
     "duration": 0.004765,
     "end_time": "2023-04-08T22:31:20.744740",
     "exception": false,
     "start_time": "2023-04-08T22:31:20.739975",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Process data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7b49ada",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-08T22:31:20.757803Z",
     "iopub.status.busy": "2023-04-08T22:31:20.756866Z",
     "iopub.status.idle": "2023-04-09T00:09:40.026565Z",
     "shell.execute_reply": "2023-04-09T00:09:40.025294Z"
    },
    "papermill": {
     "duration": 5899.279906,
     "end_time": "2023-04-09T00:09:40.029724",
     "exception": false,
     "start_time": "2023-04-08T22:31:20.749818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating TDCS list...\n",
      "Creating DEFOG list...\n",
      "Creating train data dataframes...\n"
     ]
    }
   ],
   "source": [
    "colNames_TDCS = ['Time', 'aVert', 'aML', 'aAP', 'StartHesitation', 'Turn', 'Walking', 'id_t']\n",
    "colNames_DEFOG = ['Time', 'aVert', 'aML', 'aAP', 'StartHesitation', 'Turn', 'Walking', 'Valid', 'Task', 'id_t']\n",
    "\n",
    "#features = ['maxAmpAP', 'maxAccelAmpML', 'maxAccelAmpAP', 'maxAccelAmpVert', 'rmsAmpsLowfAP', 'rmsAmpsLowfVert', 'rmsAmpsHighfML', 'QLratio_ML']\n",
    "features = ['maxAccelAmpML', 'maxAccelAmpAP', 'maxAccelAmpVert', 'rmsAmpsHighfML', 'rmsRadius_AP_Vert', 'MLmAP', 'VertmAP', 'MLbyVert', 'APbyVert']\n",
    "\n",
    "outputCols = ['StartHesitation', 'Turn', 'Walking']\n",
    "\n",
    "newColNames_TDCS = ['maxAccelAmpML', 'maxAccelAmpAP', 'maxAccelAmpVert', 'rmsAmpsHighfML', 'rmsRadius_AP_Vert', 'MLmAP', 'VertmAP', 'MLbyVert', 'APbyVert', 'StartHesitation', 'Turn', 'Walking', 'id_t']\n",
    "newColNames_DEFOG = ['maxAccelAmpML', 'maxAccelAmpAP', 'maxAccelAmpVert', 'rmsAmpsHighfML', 'rmsRadius_AP_Vert', 'MLmAP', 'VertmAP', 'MLbyVert', 'APbyVert', 'StartHesitation', 'Turn', 'Walking', 'id_t']\n",
    "\n",
    "\n",
    "trainTDCS_List = []\n",
    "trainDEFOG_List = []\n",
    "\n",
    "\n",
    "#Process data:\n",
    "print('Creating TDCS list...')\n",
    "for dirname, _, filenames in os.walk(trainTDCSFOG_path):\n",
    "    for filename in filenames:\n",
    "        #print(my_files_path+filename)\n",
    "        id = filename[:-4] #removes trailing .csv\n",
    "        f_trainTDCS_List = [] #file specific list, add elements to main list later\n",
    "        with open(trainTDCSFOG_path+filename) as file_obj:\n",
    "            heading = next(file_obj)\n",
    "            reader_obj = csv.reader(file_obj)   \n",
    "            # Iterate over each row in the csv file:\n",
    "            for row in reader_obj:\n",
    "                id_t = str(id) + \"_\" + str(row[0])\n",
    "                row.append(id_t)\n",
    "                f_trainTDCS_List.append(row)\n",
    "        #File specific list is f_trainTDCS_List\n",
    "        #Feature engineering now begins for the file:\n",
    "        numPoints = len(f_trainTDCS_List)\n",
    "        dfTemp = pd.DataFrame(f_trainTDCS_List,columns=colNames_TDCS)\n",
    "        t = np.array(dfTemp['Time'].astype('float32'))\n",
    "        aML = np.array(dfTemp['aML'].astype('float32'))\n",
    "        aAP = np.array(dfTemp['aAP'].astype('float32'))\n",
    "        aVert = np.array(dfTemp['aVert'].astype('float32'))\n",
    "        boolStartHes = np.array(dfTemp['StartHesitation'].astype('int8'))\n",
    "        boolTurn = np.array(dfTemp['Turn'].astype('int8'))\n",
    "        boolWalking = np.array(dfTemp['Walking'].astype('int8'))  \n",
    "        id_t = dfTemp['id_t'].astype('string')\n",
    "        #Pad list with zeros for now:\n",
    "        \"\"\"\n",
    "        QL_array = np.zeros(numPoints)\n",
    "        for tt in range(L_window, numPoints):\n",
    "            t_Loud = t[tt-L_window:tt-Q_window]\n",
    "            t_Quiet = t[tt-Q_window:tt]\n",
    "            ML_Loud = aML[tt-L_window:tt-Q_window]\n",
    "            ML_Quiet = aML[tt-Q_window:tt]\n",
    "            QLratio_ML = experiment1(t_Quiet, ML_Quiet, t_Loud, ML_Loud, sampleRateTDCSFOG, \"none\", dummyVariable)\n",
    "            QL_array[tt] = QLratio_ML\n",
    "            #All i've done is this for loop for tt, need to update lists, zero padding, etc.\n",
    "            #I think this will just be updating newColNames and similar for test\n",
    "            #repeat for DEFOG\n",
    "        \"\"\"\n",
    "        for k in range(0, windowHalfLength):\n",
    "            addThis = [int(0)]*(len(newColNames_TDCS)-4) #4 is number of output cols plus one for id_t\n",
    "            addThis.append(boolStartHes[k])\n",
    "            addThis.append(boolTurn[k])\n",
    "            addThis.append(boolWalking[k])\n",
    "            addThis.append(id_t.iloc[k])\n",
    "            trainTDCS_List.append(addThis)\n",
    "        for tm in range(windowHalfLength, numPoints-windowHalfLength): #got rid of minus one\n",
    "            tClip = t[tm-windowHalfLength:tm+windowHalfLength+1]\n",
    "            aML_Clip = aML[tm-windowHalfLength:tm+windowHalfLength+1]\n",
    "            aAP_Clip = aAP[tm-windowHalfLength:tm+windowHalfLength+1]\n",
    "            aVert_Clip = aVert[tm-windowHalfLength:tm+windowHalfLength+1]\n",
    "            freqML, ampsML = quickFFT_k(tClip, aML_Clip, sampleRateTDCSFOG, \"none\", dummyVariable)\n",
    "            freqAP, ampsAP = quickFFT_k(tClip, aAP_Clip, sampleRateTDCSFOG, \"none\", dummyVariable)\n",
    "            freqVert, ampsVert = quickFFT_k(tClip, aVert_Clip, sampleRateTDCSFOG, \"none\", dummyVariable)\n",
    "            absAmpsAP     = abs(ampsAP)\n",
    "            #Start Filling Arrays:\n",
    "            addThis = []\n",
    "            #addThis.append(np.amax(absAmpsAP,axis=0)) # abs val of maximum amplitude in FFT'd AP data\n",
    "            addThis.append(np.max(abs(aML_Clip)) - np.min(abs(aML_Clip)))      # abs(max - min accel) for ML accel data\n",
    "            addThis.append(np.max(abs(aAP_Clip)) - np.min(abs(aAP_Clip)))      # abs(max - min accel) for AP accel data\n",
    "            addThis.append(np.max(abs(aVert_Clip)) - np.min(abs(aVert_Clip)))  # abs(max - min accel) for Vert accel data\n",
    "            #addThis.append(getRMS(ampsAP[freqAP<lowfBandMax]))\n",
    "            #addThis.append(getRMS(ampsVert[freqVert<lowfBandMax]))\n",
    "            addThis.append(getRMS(ampsML[(freqML>highfBandMin)*(freqML<highfBandMax)]))\n",
    "            #addThis.append(QL_array[tm]) #NEW\n",
    "            addThis.append(experiment2(getRMS(ampsAP[freqAP<lowfBandMax]), getRMS(ampsVert[freqVert<lowfBandMax])))\n",
    "            addThis.append(aML[tm]-aAP[tm])\n",
    "            addThis.append(aVert[tm]-aAP[tm])\n",
    "            addThis.append(aML[tm]/aVert[tm])\n",
    "            addThis.append(aAP[tm]/aVert[tm])\n",
    "            addThis.append(boolStartHes[tm])\n",
    "            addThis.append(boolTurn[tm])\n",
    "            addThis.append(boolWalking[tm])\n",
    "            addThis.append(id_t.iloc[tm])\n",
    "            #now add to list:\n",
    "            trainTDCS_List.append(addThis)\n",
    "        #pad ending with zeros    \n",
    "        #addThis = [0]*(len(newColNames_TDCS)-1) #one because we need the id_t\n",
    "        for k in range(0, windowHalfLength):\n",
    "            addThis = [int(0)]*(len(newColNames_TDCS)-1) #one because we need the id_t\n",
    "            addThis.append(id_t.iloc[numPoints - windowHalfLength + k])\n",
    "            trainTDCS_List.append(addThis)\n",
    "\n",
    "\n",
    "#print(len(trainTDCS_List))\n",
    "\n",
    "print('Creating DEFOG list...')\n",
    "for dirname, _, filenames in os.walk(trainDEFOG_path):\n",
    "    for filename in filenames:\n",
    "        #print(my_files_path+filename)\n",
    "        id = filename[:-4] #removes trailing .csv\n",
    "        f_trainDEFOG_List = [] #file specific list, add elements to main list later\n",
    "        with open(trainDEFOG_path+filename) as file_obj:\n",
    "            heading = next(file_obj)\n",
    "            reader_obj = csv.reader(file_obj)   \n",
    "            # Iterate over each row in the csv file:\n",
    "            for row in reader_obj:\n",
    "                id_t = str(id) + \"_\" + str(row[0])\n",
    "                row.append(id_t)\n",
    "                f_trainDEFOG_List.append(row)\n",
    "        #Feature engineering now begins for the file:\n",
    "        numPoints = len(f_trainDEFOG_List)\n",
    "        dfTemp = pd.DataFrame(f_trainDEFOG_List,columns=colNames_DEFOG)\n",
    "        t = np.array(dfTemp['Time'].astype('float32'))\n",
    "        aML = np.array(dfTemp['aML'].astype('float32'))\n",
    "        aAP = np.array(dfTemp['aAP'].astype('float32'))\n",
    "        aVert = np.array(dfTemp['aVert'].astype('float32'))\n",
    "        boolStartHes = np.array(dfTemp['StartHesitation'].astype('int8'))\n",
    "        boolTurn = np.array(dfTemp['Turn'].astype('int8'))\n",
    "        boolWalking = np.array(dfTemp['Walking'].astype('int8'))  \n",
    "        id_t = dfTemp['id_t'].astype('string')\n",
    "        #Pad list with zeros for now:\n",
    "        \"\"\"\n",
    "        QL_array = np.zeros(numPoints)\n",
    "        for tt in range(L_window, numPoints):\n",
    "            t_Loud = t[tt-L_window:tt-Q_window]\n",
    "            t_Quiet = t[tt-Q_window:tt]\n",
    "            ML_Loud = aML[tt-L_window:tt-Q_window]\n",
    "            ML_Quiet = aML[tt-Q_window:tt]\n",
    "            QLratio_ML = experiment1(t_Quiet, ML_Quiet, t_Loud, ML_Loud, sampleRateDEFOG, \"none\", dummyVariable)\n",
    "            QL_array[tt] = QLratio_ML\n",
    "        \"\"\"\n",
    "        for k in range(0, windowHalfLength):\n",
    "            addThis = [int(0)]*(len(newColNames_DEFOG)-4) #4 is number of output cols plus one for id_t\n",
    "            addThis.append(boolStartHes[k])\n",
    "            addThis.append(boolTurn[k])\n",
    "            addThis.append(boolWalking[k])\n",
    "            addThis.append(id_t.iloc[k])\n",
    "            trainDEFOG_List.append(addThis)\n",
    "        for tm in range(windowHalfLength, numPoints-windowHalfLength): #got rid of minus one\n",
    "            tClip = t[tm-windowHalfLength:tm+windowHalfLength+1]\n",
    "            aML_Clip = aML[tm-windowHalfLength:tm+windowHalfLength+1]\n",
    "            aAP_Clip = aAP[tm-windowHalfLength:tm+windowHalfLength+1]\n",
    "            aVert_Clip = aVert[tm-windowHalfLength:tm+windowHalfLength+1]\n",
    "            freqML, ampsML = quickFFT_k(tClip, aML_Clip, sampleRateDEFOG, \"none\", dummyVariable)\n",
    "            freqAP, ampsAP = quickFFT_k(tClip, aAP_Clip, sampleRateDEFOG, \"none\", dummyVariable)\n",
    "            freqVert, ampsVert = quickFFT_k(tClip, aVert_Clip, sampleRateDEFOG, \"none\", dummyVariable)\n",
    "            absAmpsAP     = abs(ampsAP)\n",
    "            #Start Filling Arrays:\n",
    "            addThis = []\n",
    "            #addThis.append(np.amax(absAmpsAP,axis=0)) # abs val of maximum amplitude in FFT'd AP data\n",
    "            addThis.append(np.max(abs(aML_Clip)) - np.min(abs(aML_Clip)))      # abs(max - min accel) for ML accel data\n",
    "            addThis.append(np.max(abs(aAP_Clip)) - np.min(abs(aAP_Clip)))      # abs(max - min accel) for AP accel data\n",
    "            addThis.append(np.max(abs(aVert_Clip)) - np.min(abs(aVert_Clip)))  # abs(max - min accel) for Vert accel data\n",
    "            #addThis.append(getRMS(ampsAP[freqAP<lowfBandMax]))\n",
    "            #addThis.append(getRMS(ampsVert[freqVert<lowfBandMax]))\n",
    "            addThis.append(getRMS(ampsML[(freqML>highfBandMin)*(freqML<highfBandMax)]))\n",
    "            #addThis.append(QL_array[tm]) #NEW\n",
    "            addThis.append(experiment2(getRMS(ampsAP[freqAP<lowfBandMax]), getRMS(ampsVert[freqVert<lowfBandMax])))\n",
    "            addThis.append(aML[tm]-aAP[tm])\n",
    "            addThis.append(aVert[tm]-aAP[tm])\n",
    "            addThis.append(aML[tm]/aVert[tm])\n",
    "            addThis.append(aAP[tm]/aVert[tm])\n",
    "            addThis.append(boolStartHes[tm])\n",
    "            addThis.append(boolTurn[tm])\n",
    "            addThis.append(boolWalking[tm])\n",
    "            addThis.append(id_t.iloc[tm])\n",
    "            #now add to list:\n",
    "            trainDEFOG_List.append(addThis)\n",
    "        #pad ending with zeros    \n",
    "        #addThis = [0]*(len(newColNames_DEFOG)-1) #one because we need the id_t\n",
    "        for k in range(0, windowHalfLength):\n",
    "            addThis = [int(0)]*(len(newColNames_DEFOG)-1) #one because we need the id_t\n",
    "            addThis.append(id_t.iloc[numPoints - windowHalfLength + k])\n",
    "            trainDEFOG_List.append(addThis)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('Creating train data dataframes...')\n",
    "dfTrain_TDCS = pd.DataFrame(trainTDCS_List, columns = newColNames_TDCS)\n",
    "dfTrain_DEFOG = pd.DataFrame(trainDEFOG_List, columns = newColNames_DEFOG)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba1fabf",
   "metadata": {
    "papermill": {
     "duration": 0.00491,
     "end_time": "2023-04-09T00:09:40.040231",
     "exception": false,
     "start_time": "2023-04-09T00:09:40.035321",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "print(len(trainTDCS_List))\n",
    "print(len(trainDEFOG_List))\n",
    "print(len(trainTDCS_List[13]))\n",
    "print(len(trainDEFOG_List[13]))\n",
    "print(dfTrain_TDCS.head())\n",
    "print(dfTrain_DEFOG.head())\n",
    "print(dfTrain_TDCS.isnull().sum())\n",
    "print(dfTrain_DEFOG.isnull().sum())\n",
    "print(dfTrain_TDCS.loc[13, outputCols])\n",
    "print(dfTrain_DEFOG.loc[13, outputCols])\n",
    "print(dfTrain_TDCS.iloc[513])\n",
    "print(dfTrain_DEFOG.iloc[513])\n",
    "\n",
    "#print(dfTrain_TDCS.Turn.unique())\n",
    "#print(dfTrain_TDCS.Turn.max())\n",
    "#print(dfTrain_TDCS.Turn.min())\n",
    "#print(dfTrain_TDCS.Turn.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a94ee8d",
   "metadata": {
    "papermill": {
     "duration": 0.004906,
     "end_time": "2023-04-09T00:09:40.050256",
     "exception": false,
     "start_time": "2023-04-09T00:09:40.045350",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Train the models:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "751e8be4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T00:09:40.062801Z",
     "iopub.status.busy": "2023-04-09T00:09:40.062371Z",
     "iopub.status.idle": "2023-04-09T00:30:44.358371Z",
     "shell.execute_reply": "2023-04-09T00:30:44.354596Z"
    },
    "papermill": {
     "duration": 1264.312152,
     "end_time": "2023-04-09T00:30:44.367663",
     "exception": false,
     "start_time": "2023-04-09T00:09:40.055511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the TDCS model...\n",
      "Training the DEFOG model...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#TDCS\n",
    "print(\"Training the TDCS model...\")\n",
    "X_TDCS = dfTrain_TDCS.loc[:, features] \n",
    "y_TDCS = dfTrain_TDCS.loc[:, outputCols]\n",
    "clf_TDCS = MultiOutputClassifier(LogisticRegression(max_iter=2000, n_jobs=-1)).fit(X_TDCS, y_TDCS)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(\"Training the RF TDCS model...\")\n",
    "addl_clf_test = MultiOutputClassifier(RandomForestClassifier(n_estimators = 50, random_state = 314), n_jobs=-1).fit(X_TDCS, y_TDCS)\n",
    "\n",
    "\n",
    "feat_impts = [] \n",
    "for clf in addl_clf_test.estimators_:\n",
    "    feat_impts.append(clf.feature_importances_)\n",
    "\n",
    "print(\"Average Feature Importances: \", np.mean(feat_impts, axis=0)\n",
    "\"\"\"\n",
    "\n",
    "#DEFOG\n",
    "print(\"Training the DEFOG model...\")\n",
    "X_DEFOG = dfTrain_DEFOG.loc[:, features] \n",
    "y_DEFOG = dfTrain_DEFOG.loc[:, outputCols]\n",
    "clf_DEFOG = MultiOutputClassifier(LogisticRegression(max_iter=2000, n_jobs=-1)).fit(X_DEFOG, y_DEFOG)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c522c06d",
   "metadata": {
    "papermill": {
     "duration": 0.00537,
     "end_time": "2023-04-09T00:30:44.384493",
     "exception": false,
     "start_time": "2023-04-09T00:30:44.379123",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Now Test the model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd1cfedd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T00:30:44.401552Z",
     "iopub.status.busy": "2023-04-09T00:30:44.400407Z",
     "iopub.status.idle": "2023-04-09T00:32:09.565886Z",
     "shell.execute_reply": "2023-04-09T00:32:09.564563Z"
    },
    "papermill": {
     "duration": 85.178743,
     "end_time": "2023-04-09T00:32:09.569106",
     "exception": false,
     "start_time": "2023-04-09T00:30:44.390363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading testing files...\n",
      "Creating TDCS list...\n",
      "Creating DEFOG list...\n",
      "Creating test data dataframes...\n"
     ]
    }
   ],
   "source": [
    "#Read in test data\n",
    "print(\"Reading testing files...\")\n",
    "#test_file_path_TDCS = '/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/test/tdcsfog/003f117e14.csv'\n",
    "#test_file_path_DEFOG = '/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/test/defog/02ab235146.csv'\n",
    "\n",
    "testTDCSFOG_path = '/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/test/tdcsfog/'\n",
    "testDEFOG_path = '/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/test/defog/'\n",
    "\n",
    "testCols = ['maxAccelAmpML', 'maxAccelAmpAP', 'maxAccelAmpVert', 'rmsAmpsHighfML', 'rmsRadius_AP_Vert', 'MLmAP', 'VertmAP', 'MLbyVert', 'APbyVert', 'id_t']\n",
    "\n",
    "testTDCS_List = []\n",
    "testDEFOG_List = []\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "#Process data:\n",
    "print('Creating TDCS list...')\n",
    "for dirname, _, filenames in os.walk(testTDCSFOG_path):\n",
    "    for filename in filenames:\n",
    "        #print(my_files_path+filename)\n",
    "        id = filename[:-4] #removes trailing .csv\n",
    "        f_testTDCS_List = [] #file specific list, add elements to main list later\n",
    "        with open(testTDCSFOG_path+filename) as file_obj:\n",
    "            heading = next(file_obj)\n",
    "            reader_obj = csv.reader(file_obj)   \n",
    "            # Iterate over each row in the csv file:\n",
    "            for row in reader_obj:\n",
    "                id_t = str(id) + \"_\" + str(row[0])\n",
    "                row.append(id_t)\n",
    "                f_testTDCS_List.append(row)\n",
    "        #Feature engineering now begins for the file:\n",
    "        numPoints = len(f_testTDCS_List)\n",
    "        dfTemp = pd.DataFrame(f_testTDCS_List,columns=['Time', 'aVert', 'aML', 'aAP', 'id_t'])\n",
    "        t = np.array(dfTemp['Time'].astype('float32'))\n",
    "        aML = np.array(dfTemp['aML'].astype('float32'))\n",
    "        aAP = np.array(dfTemp['aAP'].astype('float32'))\n",
    "        aVert = np.array(dfTemp['aVert'].astype('float32'))  \n",
    "        id_t = dfTemp['id_t'].astype('string')\n",
    "        #Pad list with zeros for now:\n",
    "        #addThis = [0]*(len(testCols)-1) #one for id_t\n",
    "        \"\"\"\n",
    "        QL_array = np.zeros(numPoints)\n",
    "        for tt in range(L_window, numPoints):\n",
    "            t_Loud = t[tt-L_window:tt-Q_window]\n",
    "            t_Quiet = t[tt-Q_window:tt]\n",
    "            ML_Loud = aML[tt-L_window:tt-Q_window]\n",
    "            ML_Quiet = aML[tt-Q_window:tt]\n",
    "            QLratio_ML = experiment1(t_Quiet, ML_Quiet, t_Loud, ML_Loud, sampleRateTDCSFOG, \"none\", dummyVariable)\n",
    "            QL_array[tt] = QLratio_ML\n",
    "        \"\"\"\n",
    "        for k in range(0, windowHalfLength):\n",
    "            addThis = [0]*(len(testCols)-1) #one for id_t\n",
    "            addThis.append(id_t.iloc[k])\n",
    "            testTDCS_List.append(addThis)\n",
    "        for tm in range(windowHalfLength, numPoints-windowHalfLength): #got rid of minus one\n",
    "            tClip = t[tm-windowHalfLength:tm+windowHalfLength+1]\n",
    "            aML_Clip = aML[tm-windowHalfLength:tm+windowHalfLength+1]\n",
    "            aAP_Clip = aAP[tm-windowHalfLength:tm+windowHalfLength+1]\n",
    "            aVert_Clip = aVert[tm-windowHalfLength:tm+windowHalfLength+1]\n",
    "            freqML, ampsML = quickFFT_k(tClip, aML_Clip, sampleRateTDCSFOG, \"none\", dummyVariable)\n",
    "            freqAP, ampsAP = quickFFT_k(tClip, aAP_Clip, sampleRateTDCSFOG, \"none\", dummyVariable)\n",
    "            freqVert, ampsVert = quickFFT_k(tClip, aVert_Clip, sampleRateTDCSFOG, \"none\", dummyVariable)\n",
    "            absAmpsAP     = abs(ampsAP)\n",
    "            #Start Filling Arrays:\n",
    "            addThis = []\n",
    "            #addThis.append(np.amax(absAmpsAP,axis=0)) # abs val of maximum amplitude in FFT'd AP data\n",
    "            addThis.append(np.max(abs(aML_Clip)) - np.min(abs(aML_Clip)))      # abs(max - min accel) for ML accel data\n",
    "            addThis.append(np.max(abs(aAP_Clip)) - np.min(abs(aAP_Clip)))      # abs(max - min accel) for AP accel data\n",
    "            addThis.append(np.max(abs(aVert_Clip)) - np.min(abs(aVert_Clip)))  # abs(max - min accel) for Vert accel data\n",
    "            #addThis.append(getRMS(ampsAP[freqAP<lowfBandMax]))\n",
    "            #addThis.append(getRMS(ampsVert[freqVert<lowfBandMax]))\n",
    "            addThis.append(getRMS(ampsML[(freqML>highfBandMin)*(freqML<highfBandMax)]))\n",
    "            #addThis.append(QL_array[tm]) #NEW\n",
    "            addThis.append(experiment2(getRMS(ampsAP[freqAP<lowfBandMax]), getRMS(ampsVert[freqVert<lowfBandMax])))\n",
    "            addThis.append(aML[tm]-aAP[tm])\n",
    "            addThis.append(aVert[tm]-aAP[tm])\n",
    "            addThis.append(aML[tm]/aVert[tm])\n",
    "            addThis.append(aAP[tm]/aVert[tm])\n",
    "            addThis.append(id_t.iloc[tm])\n",
    "            #now add to list:\n",
    "            testTDCS_List.append(addThis)\n",
    "        #pad ending with zeros    \n",
    "        #addThis = [0]*(len(testCols)-1) #one because we need the id_t\n",
    "        for k in range(0, windowHalfLength):\n",
    "            addThis = [0]*(len(testCols)-1) #one because we need the id_t\n",
    "            addThis.append(id_t.iloc[numPoints - windowHalfLength + k])\n",
    "            testTDCS_List.append(addThis)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('Creating DEFOG list...')\n",
    "for dirname, _, filenames in os.walk(testDEFOG_path):\n",
    "    for filename in filenames:\n",
    "        #print(my_files_path+filename)\n",
    "        id = filename[:-4] #removes trailing .csv\n",
    "        f_testDEFOG_List = [] #file specific list, add elements to main list later\n",
    "        with open(testDEFOG_path+filename) as file_obj:\n",
    "            heading = next(file_obj)\n",
    "            reader_obj = csv.reader(file_obj)   \n",
    "            # Iterate over each row in the csv file:\n",
    "            for row in reader_obj:\n",
    "                id_t = str(id) + \"_\" + str(row[0])\n",
    "                row.append(id_t)\n",
    "                f_testDEFOG_List.append(row)\n",
    "        #Feature engineering now begins for the file:\n",
    "        numPoints = len(f_testDEFOG_List)\n",
    "        dfTemp = pd.DataFrame(f_testDEFOG_List,columns=['Time', 'aVert', 'aML', 'aAP', 'id_t'])\n",
    "        t = np.array(dfTemp['Time'].astype('float32'))\n",
    "        aML = np.array(dfTemp['aML'].astype('float32'))\n",
    "        aAP = np.array(dfTemp['aAP'].astype('float32'))\n",
    "        aVert = np.array(dfTemp['aVert'].astype('float32'))  \n",
    "        id_t = dfTemp['id_t'].astype('string')\n",
    "        #Pad list with zeros for now:\n",
    "        #addThis = [0]*(len(testCols)-1) #one for id_t\n",
    "        \"\"\"\n",
    "        QL_array = np.zeros(numPoints)\n",
    "        for tt in range(L_window, numPoints):\n",
    "            t_Loud = t[tt-L_window:tt-Q_window]\n",
    "            t_Quiet = t[tt-Q_window:tt]\n",
    "            ML_Loud = aML[tt-L_window:tt-Q_window]\n",
    "            ML_Quiet = aML[tt-Q_window:tt]\n",
    "            QLratio_ML = experiment1(t_Quiet, ML_Quiet, t_Loud, ML_Loud, sampleRateDEFOG, \"none\", dummyVariable)\n",
    "            QL_array[tt] = QLratio_ML\n",
    "        \"\"\"\n",
    "        for k in range(0, windowHalfLength):\n",
    "            addThis = [0]*(len(testCols)-1) #one for id_t\n",
    "            addThis.append(id_t.iloc[k])\n",
    "            testDEFOG_List.append(addThis)\n",
    "        for tm in range(windowHalfLength, numPoints-windowHalfLength): #got rid of minus one\n",
    "            tClip = t[tm-windowHalfLength:tm+windowHalfLength+1]\n",
    "            aML_Clip = aML[tm-windowHalfLength:tm+windowHalfLength+1]\n",
    "            aAP_Clip = aAP[tm-windowHalfLength:tm+windowHalfLength+1]\n",
    "            aVert_Clip = aVert[tm-windowHalfLength:tm+windowHalfLength+1]\n",
    "            freqML, ampsML = quickFFT_k(tClip, aML_Clip, sampleRateDEFOG, \"none\", dummyVariable)\n",
    "            freqAP, ampsAP = quickFFT_k(tClip, aAP_Clip, sampleRateDEFOG, \"none\", dummyVariable)\n",
    "            freqVert, ampsVert = quickFFT_k(tClip, aVert_Clip, sampleRateDEFOG, \"none\", dummyVariable)\n",
    "            absAmpsAP     = abs(ampsAP)\n",
    "            #Start Filling Arrays:\n",
    "            addThis = []\n",
    "            #addThis.append(np.amax(absAmpsAP,axis=0)) # abs val of maximum amplitude in FFT'd AP data\n",
    "            addThis.append(np.max(abs(aML_Clip)) - np.min(abs(aML_Clip)))      # abs(max - min accel) for ML accel data\n",
    "            addThis.append(np.max(abs(aAP_Clip)) - np.min(abs(aAP_Clip)))      # abs(max - min accel) for AP accel data\n",
    "            addThis.append(np.max(abs(aVert_Clip)) - np.min(abs(aVert_Clip)))  # abs(max - min accel) for Vert accel data\n",
    "            #addThis.append(getRMS(ampsAP[freqAP<lowfBandMax]))\n",
    "            #addThis.append(getRMS(ampsVert[freqVert<lowfBandMax]))\n",
    "            addThis.append(getRMS(ampsML[(freqML>highfBandMin)*(freqML<highfBandMax)]))\n",
    "            #addThis.append(QL_array[tm]) #NEW\n",
    "            addThis.append(experiment2(getRMS(ampsAP[freqAP<lowfBandMax]), getRMS(ampsVert[freqVert<lowfBandMax])))\n",
    "            addThis.append(aML[tm]-aAP[tm])\n",
    "            addThis.append(aVert[tm]-aAP[tm])\n",
    "            addThis.append(aML[tm]/aVert[tm])\n",
    "            addThis.append(aAP[tm]/aVert[tm])\n",
    "            addThis.append(id_t.iloc[tm])\n",
    "            #now add to list:\n",
    "            testDEFOG_List.append(addThis)\n",
    "        #pad ending with zeros    \n",
    "        #addThis = [0]*(len(testCols)-1) #one because we need the id_t\n",
    "        for k in range(0, windowHalfLength):\n",
    "            addThis = [0]*(len(testCols)-1) #one because we need the id_t\n",
    "            addThis.append(id_t.iloc[numPoints - windowHalfLength + k])\n",
    "            testDEFOG_List.append(addThis)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "print('Creating test data dataframes...')\n",
    "dfTest_TDCS = pd.DataFrame(testTDCS_List, columns = testCols)\n",
    "dfTest_DEFOG = pd.DataFrame(testDEFOG_List, columns = testCols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc4caa53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T00:32:09.582920Z",
     "iopub.status.busy": "2023-04-09T00:32:09.582498Z",
     "iopub.status.idle": "2023-04-09T00:32:11.824627Z",
     "shell.execute_reply": "2023-04-09T00:32:11.823489Z"
    },
    "papermill": {
     "duration": 2.252531,
     "end_time": "2023-04-09T00:32:11.827448",
     "exception": false,
     "start_time": "2023-04-09T00:32:09.574917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making TDCS predictions...\n",
      "Making DEFOG predictions...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#TDCS\n",
    "X_val_TDCS = dfTest_TDCS.loc[:, features]\n",
    "print(\"Making TDCS predictions...\")\n",
    "clf_predictions_TDCS = clf_TDCS.predict_proba(X_val_TDCS)\n",
    "startHesProb = []\n",
    "turnProb = []\n",
    "walkingProb = []\n",
    "\n",
    "for i in range(0, len(clf_predictions_TDCS[0])):\n",
    "    #[class][data point][prob of no event = 0 prob of event = 1]\n",
    "    mx = np.argmax([clf_predictions_TDCS[0][i][1], clf_predictions_TDCS[1][i][1], clf_predictions_TDCS[2][i][1]])\n",
    "    #print(mx)\n",
    "    #print(clf_predictions_TDCS[i])\n",
    "    if mx==0:\n",
    "        startHesProb.append(clf_predictions_TDCS[0][i][1])\n",
    "        turnProb.append(0)\n",
    "        walkingProb.append(0)\n",
    "    elif mx==1:\n",
    "        startHesProb.append(0)\n",
    "        turnProb.append(clf_predictions_TDCS[1][i][1])\n",
    "        walkingProb.append(0)\n",
    "    elif mx==2:\n",
    "        startHesProb.append(0)\n",
    "        turnProb.append(0)\n",
    "        walkingProb.append(clf_predictions_TDCS[2][i][1])\n",
    "    else:\n",
    "        startHesProb.append(0)\n",
    "        turnProb.append(0)\n",
    "        walkingProb.append(0)\n",
    "\n",
    "df_clf_predictions_TDCS = pd.DataFrame()\n",
    "df_clf_predictions_TDCS['StartHesitation'] = startHesProb\n",
    "df_clf_predictions_TDCS['Turn'] = turnProb\n",
    "df_clf_predictions_TDCS['Walking'] = walkingProb\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#DEFOG:\n",
    "X_val_DEFOG = dfTest_DEFOG.loc[:, features]\n",
    "print(\"Making DEFOG predictions...\")\n",
    "clf_predictions_DEFOG = clf_DEFOG.predict_proba(X_val_DEFOG)\n",
    "startHesProb = []\n",
    "turnProb = []\n",
    "walkingProb = []\n",
    "\n",
    "for i in range(0, len(clf_predictions_DEFOG[0])):\n",
    "    #[class][data point][prob of no event = 0 prob of event = 1]\n",
    "    mx = np.argmax([clf_predictions_DEFOG[0][i][1], clf_predictions_DEFOG[1][i][1], clf_predictions_DEFOG[2][i][1]])\n",
    "    if mx==0:\n",
    "        startHesProb.append(clf_predictions_DEFOG[0][i][1])\n",
    "        turnProb.append(0)\n",
    "        walkingProb.append(0)\n",
    "    elif mx==1:\n",
    "        startHesProb.append(0)\n",
    "        turnProb.append(clf_predictions_DEFOG[1][i][1])\n",
    "        walkingProb.append(0)\n",
    "    elif mx==2:\n",
    "        startHesProb.append(0)\n",
    "        turnProb.append(0)\n",
    "        walkingProb.append(clf_predictions_DEFOG[2][i][1])\n",
    "    else:\n",
    "        startHesProb.append(0)\n",
    "        turnProb.append(0)\n",
    "        walkingProb.append(0)\n",
    "\n",
    "df_clf_predictions_DEFOG = pd.DataFrame()\n",
    "df_clf_predictions_DEFOG['StartHesitation'] = startHesProb\n",
    "df_clf_predictions_DEFOG['Turn'] = turnProb\n",
    "df_clf_predictions_DEFOG['Walking'] = walkingProb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7038757f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T00:32:11.841738Z",
     "iopub.status.busy": "2023-04-09T00:32:11.841012Z",
     "iopub.status.idle": "2023-04-09T00:32:11.845651Z",
     "shell.execute_reply": "2023-04-09T00:32:11.844709Z"
    },
    "papermill": {
     "duration": 0.014729,
     "end_time": "2023-04-09T00:32:11.848189",
     "exception": false,
     "start_time": "2023-04-09T00:32:11.833460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#skip post processing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "defd475c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T00:32:11.862156Z",
     "iopub.status.busy": "2023-04-09T00:32:11.861699Z",
     "iopub.status.idle": "2023-04-09T00:32:12.940069Z",
     "shell.execute_reply": "2023-04-09T00:32:12.939098Z"
    },
    "papermill": {
     "duration": 1.088747,
     "end_time": "2023-04-09T00:32:12.942832",
     "exception": false,
     "start_time": "2023-04-09T00:32:11.854085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing submission file...\n"
     ]
    }
   ],
   "source": [
    "#store df of submission results.\n",
    "finalCols = ['Id', 'StartHesitation', 'Turn', 'Walking']\n",
    "\n",
    "id_t_TDCS = dfTest_TDCS.loc[:, 'id_t']\n",
    "id_t_DEFOG = dfTest_DEFOG.loc[:, 'id_t']\n",
    "\n",
    "#print(dfTest_TDCS.loc[:, 'id_t'])\n",
    "#print(dfTest_DEFOG.loc[:, 'id_t'])\n",
    "\n",
    "\n",
    "df_clf_predictions_TDCS['Id'] =  id_t_TDCS\n",
    "df_clf_predictions_DEFOG['Id'] = id_t_DEFOG\n",
    "\n",
    "df_TDCS = df_clf_predictions_TDCS[finalCols]\n",
    "df_DEFOG = df_clf_predictions_DEFOG[finalCols]\n",
    "\n",
    "output_df = pd.concat([df_TDCS, df_DEFOG], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(len(output_df))\n",
    "print(output_df.dtypes)\n",
    "samp = pd.read_csv('/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/sample_submission.csv')\n",
    "print(len(samp))\n",
    "print(samp.dtypes)\n",
    "\n",
    "print(output_df.head())\n",
    "print(samp.head())\n",
    "\n",
    "print(output_df.tail())\n",
    "print(samp.tail())\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "print('Writing submission file...')\n",
    "output_df.to_csv(\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5bbba8",
   "metadata": {
    "papermill": {
     "duration": 0.005756,
     "end_time": "2023-04-09T00:32:12.954957",
     "exception": false,
     "start_time": "2023-04-09T00:32:12.949201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7267.879195,
   "end_time": "2023-04-09T00:32:16.710518",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-08T22:31:08.831323",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
